{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install pyspark sparknlp numpy scikit-learn tqdm --upgrade transformers torch --upgrade accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# üîß T·∫£i tokenizer v√† model PhoBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
    "model = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
    "model.eval()\n",
    "\n",
    "# üìÇ ƒê·ªçc d·ªØ li·ªáu JSONL\n",
    "file_path = \"/opt/workspace/data.jsonl\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "# üéØ L·ªçc v√† k·∫øt h·ª£p user-assistant th√†nh c√°c ƒëo·∫°n h·ªôi tho·∫°i\n",
    "conversations = []\n",
    "for item in data:\n",
    "    messages = item.get(\"messages\", [])\n",
    "    pair = {}\n",
    "    for m in messages:\n",
    "        if m[\"role\"] == \"assistant\" and m.get(\"content\") is None:\n",
    "            pair = None\n",
    "            break\n",
    "        if m[\"role\"] == \"user\":\n",
    "            pair[\"user\"] = m[\"content\"]\n",
    "        elif m[\"role\"] == \"assistant\":\n",
    "            pair[\"assistant\"] = m[\"content\"]\n",
    "    if pair and \"user\" in pair and \"assistant\" in pair:\n",
    "        conversations.append(pair)\n",
    "\n",
    "# ‚ú® Tr√≠ch xu·∫•t embedding t·ª´ c√¢u h·ªèi user (PhoBERT)\n",
    "def get_embedding(text):\n",
    "    input_ids = tokenizer.encode(text, return_tensors=\"pt\", max_length=256, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids)[0]\n",
    "        embedding = output.mean(dim=1).squeeze().numpy()\n",
    "    return embedding\n",
    "\n",
    "questions = [conv[\"user\"] for conv in conversations]\n",
    "answers = [conv[\"assistant\"] for conv in conversations]\n",
    "embeddings = [get_embedding(q) for q in tqdm(questions, desc=\"Embedding\")]\n",
    "\n",
    "# üîç Nh√≥m theo ng·ªØ nghƒ©a ƒë·ªÉ lo·∫°i tr√πng l·∫∑p\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "distance_matrix = np.clip(1 - similarity_matrix, 0, None)\n",
    "dbscan = DBSCAN(metric=\"precomputed\", eps=0.1, min_samples=1).fit(distance_matrix)\n",
    "\n",
    "# üßπ Gi·ªØ l·∫°i 1 c√¢u h·ªèi ƒë·∫°i di·ªán cho m·ªói nh√≥m\n",
    "selected_indices = {label: idx for idx, label in enumerate(dbscan.labels_)}.values()\n",
    "cleaned_data = []\n",
    "for i in selected_indices:\n",
    "    cleaned_data.append({\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": questions[i]},\n",
    "            {\"role\": \"assistant\", \"content\": answers[i]}\n",
    "        ]\n",
    "    })\n",
    "\n",
    "# üìù Ghi ra file JSONL\n",
    "output_path = \"/opt/workspace/clean_conversations.jsonl\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in cleaned_data:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u file t·∫°i: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
