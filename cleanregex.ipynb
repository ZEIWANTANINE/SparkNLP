{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e976c471",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install pyspark sparknlp numpy scikit-learn tqdm --upgrade transformers torch accelerate\n",
    "\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# üîß Load PhoBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
    "model = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
    "model.eval()\n",
    "\n",
    "# üìÇ Load JSONL data\n",
    "file_path = \"/opt/workspace/data.jsonl\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "# üéØ Extract user-assistant pairs & clean invalid assistant responses\n",
    "conversations = []\n",
    "for item in data:\n",
    "    messages = item.get(\"messages\", [])\n",
    "    pair = {}\n",
    "    for m in messages:\n",
    "        if m[\"role\"] == \"assistant\":\n",
    "            if m.get(\"content\") is None or \"can not solve\" in m.get(\"content\", \"\").lower():\n",
    "                pair = None\n",
    "                break\n",
    "            pair[\"assistant\"] = m[\"content\"]\n",
    "        elif m[\"role\"] == \"user\":\n",
    "            pair[\"user\"] = m[\"content\"]\n",
    "    if pair and \"user\" in pair and \"assistant\" in pair:\n",
    "        conversations.append(pair)\n",
    "\n",
    "# ‚ú® T·∫°o embedding t·ª´ user question b·∫±ng PhoBERT\n",
    "def get_embedding(text):\n",
    "    input_ids = tokenizer.encode(text, return_tensors=\"pt\", max_length=256, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids)[0]\n",
    "        embedding = output.mean(dim=1).squeeze().numpy()\n",
    "    return embedding\n",
    "\n",
    "questions = [conv[\"user\"] for conv in conversations]\n",
    "answers = [conv[\"assistant\"] for conv in conversations]\n",
    "\n",
    "# üß† Chu·∫©n h√≥a c√¢u h·ªèi ƒë·ªÉ l·ªçc theo m·∫´u chung\n",
    "def normalize_question(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = re.sub(r\"cho t√¥i th√¥ng tin c·ªßa [\\w\\s\\.\\-]+\", \"cho t√¥i th√¥ng tin c·ªßa ...\", text)\n",
    "    text = re.sub(r\"c√≥ bao nhi√™u thi·∫øt b·ªã [\\w\\s]+ t·∫°i [\\w\\s]+\", \"c√≥ bao nhi√™u thi·∫øt b·ªã ... t·∫°i ...\", text)\n",
    "    text = re.sub(r\"c√≥ bao nhi√™u thi·∫øt b·ªã [\\w\\s]+\", \"c√≥ bao nhi√™u thi·∫øt b·ªã ...\", text)\n",
    "    text = re.sub(r\"thi·∫øt b·ªã [\\w\\s]+ c√≥ nh·ªØng thu·ªôc t√≠nh g√¨\", \"thi·∫øt b·ªã ... c√≥ nh·ªØng thu·ªôc t√≠nh g√¨\", text)\n",
    "    text = re.sub(r\"cho t√¥i bi·∫øt th√¥ng tin\", \" \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\"cho t√¥i bi·∫øt s·ªë l∆∞·ª£ng\", \" \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\"cho t√¥i bi·∫øt th√¥ng tin nh·ªØng thi·∫øt b·ªã\", \" \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\"th·ªëng k√™\", \" \", text, flags=re.IGNORECASE)\n",
    "    return text.strip()\n",
    "\n",
    "normalized_questions = [normalize_question(q) for q in questions]\n",
    "\n",
    "# üßπ L·∫•y ch·ªâ 1 c√¢u ƒë·∫°i di·ªán cho m·ªói d·∫°ng m·∫´u\n",
    "unique_indices = {}\n",
    "for idx, norm_q in enumerate(normalized_questions):\n",
    "    if norm_q not in unique_indices:\n",
    "        unique_indices[norm_q] = idx\n",
    "\n",
    "filtered_questions = [questions[i] for i in unique_indices.values()]\n",
    "filtered_answers = [answers[i] for i in unique_indices.values()]\n",
    "\n",
    "# üß† L·∫•y embedding v√† so s√°nh ƒë·ªô t∆∞∆°ng ƒë·ªìng ƒë·ªÉ lo·∫°i tr√πng theo nghƒ©a\n",
    "embeddings = [get_embedding(q) for q in tqdm(filtered_questions, desc=\"Embedding\")]\n",
    "\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "distance_matrix = np.clip(1 - similarity_matrix, 0, None)\n",
    "dbscan = DBSCAN(metric=\"precomputed\", eps=0.1, min_samples=1).fit(distance_matrix)\n",
    "\n",
    "# üßπ Gi·ªØ l·∫°i 1 c√¢u h·ªèi ƒë·∫°i di·ªán cho m·ªói c·ª•m ng·ªØ nghƒ©a\n",
    "selected_indices = {label: idx for idx, label in enumerate(dbscan.labels_)}.values()\n",
    "cleaned_data = []\n",
    "for i in selected_indices:\n",
    "    cleaned_data.append({\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": filtered_questions[i]},\n",
    "            {\"role\": \"assistant\", \"content\": filtered_answers[i]}\n",
    "        ]\n",
    "    })\n",
    "\n",
    "# üíæ Xu·∫•t ra file\n",
    "output_path = \"/opt/workspace/clean_conversations.jsonl\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in cleaned_data:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u file s·∫°ch t·∫°i: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4970b22c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
