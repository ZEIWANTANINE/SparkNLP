{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d82946",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pip install pyspark spark-nlp pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca07f0c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, explode, udf, lower, trim, regexp_replace, count\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.base import DocumentAssembler\n",
    "from sparknlp.annotator import Tokenizer, DeBertaEmbeddings\n",
    "\n",
    "# Khởi tạo Spark NLP\n",
    "spark = sparknlp.start()\n",
    "\n",
    "# Đọc dữ liệu từ file JSONL\n",
    "input_file_path = \"/opt/workspace/data.jsonl\"\n",
    "df = spark.read.option(\"multiLine\", False).json(input_file_path)\n",
    "\n",
    "# Trích xuất câu hỏi từ role là \"user\"\n",
    "user_questions = df.select(explode(\"messages\").alias(\"msg\")) \\\n",
    "    .filter(col(\"msg.role\") == \"user\") \\\n",
    "    .select(col(\"msg.content\").alias(\"text\")) \\\n",
    "    .filter(col(\"text\").isNotNull())\n",
    "\n",
    "# Tạo pipeline NLP\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "embeddings = DeBertaEmbeddings.pretrained(\"deberta_embeddings_spm_vie\", \"vie\") \\\n",
    "    .setInputCols([\"document\", \"token\"]) \\\n",
    "    .setOutputCol(\"embeddings\") \\\n",
    "    .setCaseSensitive(True)\n",
    "\n",
    "pipeline = Pipeline(stages=[document_assembler, tokenizer, embeddings])\n",
    "\n",
    "# Chạy pipeline\n",
    "model = pipeline.fit(user_questions)\n",
    "embedded_data = model.transform(user_questions)\n",
    "\n",
    "# UDF để tính vector trung bình từ embedding\n",
    "def avg_embeddings(embeddings):\n",
    "    if embeddings:\n",
    "        avg = np.mean([e['embeddings'] for e in embeddings], axis=0)\n",
    "        return Vectors.dense(avg.tolist())\n",
    "    return Vectors.dense([])\n",
    "\n",
    "avg_embeddings_udf = udf(avg_embeddings, VectorUDT())\n",
    "\n",
    "# Chuyển thành vector đặc trưng\n",
    "vectorized_data = embedded_data.withColumn(\"features\", avg_embeddings_udf(col(\"embeddings\")))\n",
    "\n",
    "# Chuẩn hóa vector\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "scaler_model = scaler.fit(vectorized_data)\n",
    "scaled_data = scaler_model.transform(vectorized_data)\n",
    "\n",
    "# KMeans clustering\n",
    "kmeans = KMeans(featuresCol=\"scaled_features\", predictionCol=\"cluster\", k=3)\n",
    "kmeans_model = kmeans.fit(scaled_data)\n",
    "clustered_data = kmeans_model.transform(scaled_data)\n",
    "\n",
    "# Chuẩn hóa text: chỉ loại dấu câu, giữ nguyên tiếng Việt\n",
    "normalized_data = clustered_data.withColumn(\n",
    "    \"normalized_text\",\n",
    "    trim(lower(regexp_replace(col(\"text\"), \"[\\\\p{Punct}]\", \"\")))\n",
    ")\n",
    "\n",
    "# Đếm tần suất các câu hỏi sau khi normalize\n",
    "grouped = normalized_data.groupBy(\"normalized_text\", \"cluster\") \\\n",
    "    .agg(count(\"*\").alias(\"frequency\")) \\\n",
    "    .orderBy(col(\"frequency\").desc())\n",
    "\n",
    "# Hiển thị kết quả\n",
    "grouped.show(truncate=False)\n",
    "\n",
    "# Vẽ biểu đồ tần suất theo cụm\n",
    "cluster_counts = grouped.groupBy(\"cluster\").sum(\"frequency\") \\\n",
    "    .withColumnRenamed(\"sum(frequency)\", \"count\") \\\n",
    "    .orderBy(\"cluster\") \\\n",
    "    .toPandas()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(cluster_counts[\"cluster\"], cluster_counts[\"count\"], color=\"teal\")\n",
    "plt.xlabel(\"Cluster ID\")\n",
    "plt.ylabel(\"Number of Questions\")\n",
    "plt.title(\"Semantic Question Clustering Frequency\")\n",
    "plt.xticks(cluster_counts[\"cluster\"])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
