{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8423df-aa0c-4137-992e-2bb6a6f8c0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai pandas matplotlib seaborn spark-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dae8a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "import pandas as pd\n",
    "import json\n",
    "import openai\n",
    "import sparknlp\n",
    "from pyspark.sql import SparkSession\n",
    "spark = sparknlp.start()\n",
    "# âš™ï¸ Load Spark NLP pipeline\n",
    "pipeline = PretrainedPipeline(\"explain_document_dl\", lang=\"vi\")\n",
    "\n",
    "# ğŸ“¥ Äá»c dá»¯ liá»‡u\n",
    "with open(\"/opt/workspace/gen_1604_formated.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "# ğŸ“Œ TrÃ­ch cÃ¢u há»i ngÆ°á»i dÃ¹ng\n",
    "questions = [\n",
    "    m[\"content\"].strip()\n",
    "    for item in data\n",
    "    for m in item.get(\"messages\", [])\n",
    "    if m[\"role\"] == \"user\"\n",
    "]\n",
    "\n",
    "# ğŸ§  Gom nhÃ³m theo tá»« khÃ³a chá»§ Ä‘á»\n",
    "semantic_groups = {}\n",
    "for q in questions:\n",
    "    try:\n",
    "        result = pipeline.annotate(q)\n",
    "        keywords = result.get(\"entities\", []) + result.get(\"keywords\", []) + result.get(\"noun_chunks\", [])\n",
    "        keywords = [kw.lower() for kw in keywords if kw.strip()]\n",
    "        key = \"|\".join(sorted(set(keywords)))\n",
    "        if key:\n",
    "            semantic_groups.setdefault(key, []).append(q)\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Lá»—i xá»­ lÃ½ cÃ¢u: {q}\\n{e}\")\n",
    "\n",
    "# ğŸ“Š Gom nhÃ³m & chá»n Ä‘áº¡i diá»‡n\n",
    "grouped_data = []\n",
    "for key, qs in semantic_groups.items():\n",
    "    if len(qs) < 2:\n",
    "        continue  # bá» qua nhÃ³m chá»‰ cÃ³ 1 cÃ¢u\n",
    "    representative = sorted(qs, key=len)[0]  # láº¥y cÃ¢u ngáº¯n nháº¥t lÃ m Ä‘áº¡i diá»‡n\n",
    "    grouped_data.append((len(qs), key, representative))\n",
    "\n",
    "# ğŸ§¹ Sáº¯p xáº¿p theo táº§n suáº¥t giáº£m dáº§n\n",
    "grouped_data.sort(reverse=True)\n",
    "\n",
    "# ğŸ”‘ GPT dÃ¹ng Ä‘á»ƒ Ä‘áº·t tÃªn chá»§ Ä‘á» cho nhÃ³m\n",
    "openai.api_key = \"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\"  # Äiá»n API key\n",
    "\n",
    "# ğŸ§¾ Táº¡o prompt Ä‘á»ƒ Ä‘áº·t tÃªn nhÃ³m\n",
    "topic_prompt = \"HÃ£y Ä‘áº·t tiÃªu Ä‘á» chá»§ Ä‘á» ngáº¯n gá»n cho má»—i nhÃ³m tá»« khÃ³a sau.\\n\" \\\n",
    "               \"Tráº£ vá» dáº¡ng: `Tá»« khÃ³a | Chá»§ Ä‘á»`\\nKhÃ´ng giáº£i thÃ­ch.\\n\\n\" + \\\n",
    "               \"\\n\".join(f\"- {key}\" for _, key, _ in grouped_data[:20])\n",
    "\n",
    "# ğŸ”— Gá»i GPT\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.1,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch vÃ  Ä‘áº·t tÃªn chá»§ Ä‘á» ngáº¯n gá»n tá»« tá»« khÃ³a.\"},\n",
    "        {\"role\": \"user\", \"content\": topic_prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ğŸ“¥ Láº¥y tÃªn chá»§ Ä‘á» tá»« pháº£n há»“i\n",
    "lines = response.choices[0].message.content.strip().splitlines()\n",
    "topic_map = {}\n",
    "for line in lines:\n",
    "    if \"|\" in line:\n",
    "        parts = line.split(\"|\", maxsplit=1)\n",
    "        topic_map[parts[0].strip().lower()] = parts[1].strip()\n",
    "\n",
    "# ğŸ“‹ In báº£ng káº¿t quáº£\n",
    "print(\"ğŸ“‹ Táº¦N SUáº¤T CÃC NHÃ“M CÃ‚U Há»I (Spark NLP + GPT):\\n\")\n",
    "print(\"Sá»‘ lÆ°á»£ng | Chá»§ Ä‘á»             | CÃ¢u há»i Ä‘áº¡i diá»‡n\")\n",
    "print(\"---------|--------------------|-------------------------------\")\n",
    "for count, key, rep in grouped_data[:20]:\n",
    "    topic = topic_map.get(key.lower(), \"ChÆ°a Ä‘áº·t tÃªn\")\n",
    "    print(f\"{count:<9} | {topic:<20} | {rep}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
